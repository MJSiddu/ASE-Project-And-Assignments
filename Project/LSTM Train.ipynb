{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "C:\\Users\\siddu\\Documents\\COURSES\\ASE\\Project\n",
      "Clustering.ipynb\n",
      "body_pp.dpkl\n",
      "issues_labeller\n",
      "issues_labeller.tar\n",
      "predictor.ipynb\n",
      "preprocess_data.ipynb\n",
      "test_body_vecs.npy\n",
      "test_labels.npy\n",
      "test_title_vecs.npy\n",
      "testdf.pkl\n",
      "title_pp.dpkl\n",
      "train_body_vecs.npy\n",
      "train_labels.npy\n",
      "train_model.ipynb\n",
      "train_title_vecs.npy\n",
      "traindf.pkl\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Embedding, BatchNormalization, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import dill as dpickle\n",
    "print(tf.__version__)\n",
    "print(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    1  171    1    3   67]\n",
      " [   0    0    0    0    0    0    0   11  450 3105]\n",
      " [   0    0    0    0    0    0   49   81    1    1]\n",
      " [   0    0    0  102  181   17   14    1  315 1047]\n",
      " [   0    0    0    0    0    0   49  434 3206  150]\n",
      " [   0    0    0    0    0    0  263 1023  112 1321]\n",
      " [   0    0    0    0   37 1297  209    5  204  733]\n",
      " [   0    0    0    0    0    0  769    8 1456  230]\n",
      " [ 240  176  149 1021   56    3    8  194  123  124]\n",
      " [   0    0    0    0    0    1  702  352  128    1]]\n",
      "(1871144, 110)\n",
      "(1871144, 10)\n"
     ]
    }
   ],
   "source": [
    "with open('title_pp.dpkl', 'rb') as f:\n",
    "    title_pp = dpickle.load(f)\n",
    "\n",
    "with open('body_pp.dpkl', 'rb') as f:\n",
    "    body_pp = dpickle.load(f)\n",
    "    \n",
    "#load the training data and labels\n",
    "train_body_vecs = np.load('train_body_vecs.npy')\n",
    "train_title_vecs = np.load('train_title_vecs.npy')\n",
    "train_labels = np.load('train_labels.npy')\n",
    "\n",
    "#load the test data and labels\n",
    "test_body_vecs = np.load('test_body_vecs.npy')\n",
    "test_title_vecs = np.load('test_title_vecs.npy')\n",
    "test_labels = np.load('test_labels.npy')\n",
    "\n",
    "\n",
    "issue_body_doc_length = train_body_vecs.shape[:]\n",
    "issue_title_doc_length = train_title_vecs.shape[:]\n",
    "\n",
    "body_vocab_size = body_pp.n_tokens\n",
    "title_vocab_size = title_pp.n_tokens\n",
    "\n",
    "num_classes = len(set(train_labels[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_input = Input(shape=(issue_body_doc_length,), name='Body-Input')\n",
    "title_input = Input(shape=(issue_title_doc_length,), name='Title-Input')\n",
    "\n",
    "body = Embedding(body_vocab_size, 50, name='Body-Embedding')(body_input)\n",
    "title = Embedding(title_vocab_size, 50, name='Title-Embedding')(title_input)\n",
    "\n",
    "body = BatchNormalization()(body)\n",
    "body = GRU(100, name='Body-Encoder')(body)\n",
    "\n",
    "title = BatchNormalization()(title)\n",
    "title = GRU(75, name='Title-Encoder')(title)\n",
    "\n",
    "x = Concatenate(name='Concat')([body, title])\n",
    "x = BatchNormalization()(x)\n",
    "out = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model([body_input, title_input], out)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "script_name_base = 'Issue_Label_v1'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "model_checkpoint = ModelCheckpoint('{:}_best_model.hdf5'.format(script_name_base),\n",
    "                                   save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 900\n",
    "epochs = 4\n",
    "history = model.fit(x=[train_body_vecs, train_title_vecs], \n",
    "                    y=train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=[(test_body_vecs, test_title_vecs), test_labels], \n",
    "                    callbacks=[csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
